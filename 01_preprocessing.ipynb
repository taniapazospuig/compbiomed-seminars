{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/full_data_corrected_2024.pkl', 'rb') as file:\n",
    "    full_data = pickle.load(file)\n",
    "\n",
    "print(type(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an index to inspect (the first sample)\n",
    "i = 0\n",
    "\n",
    "# Print out all values for that sample\n",
    "for key in full_data.keys():\n",
    "    value = full_data[key][i]\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a full ECG record, including:\n",
    "* Raw 12-lead signals, each one a NumPy array\n",
    "* Patient metadata: Sex, HTA, PVC_transition, SOO_chamber, Height, Weight, BMI, DM, DLP, Smoker, COPD, Sleep_apnea, CLINICAL_SCORE, SOO, OTorigin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of samples (smame for all keys)\n",
    "print(len(full_data['PVC_transition']))\n",
    "# Convert to a dataframe for easier manipulation\n",
    "\n",
    "metadata_keys = ['Sex', 'HTA', 'Age', 'PVC_transition', 'SOO_chamber', 'Height', 'Weight', 'BMI', \n",
    "                 'DM', 'DLP', 'Smoker', 'COPD', 'Sleep_apnea', 'CLINICAL_SCORE', 'SOO', 'OTorigin']\n",
    "\n",
    "df_meta = pd.DataFrame({key: full_data[key] for key in metadata_keys})\n",
    "\n",
    "df_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_meta['SOO_chamber'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multi-lead ECG array\n",
    "ecg_leads = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "n_samples = len(full_data['I'])\n",
    "signal_length = len(full_data['I'][0])  # assuming all leads same length\n",
    "\n",
    "multi_lead_ecgs = np.zeros((n_samples, len(ecg_leads), signal_length))\n",
    "for i, lead in enumerate(ecg_leads):\n",
    "    for j in range(n_samples):\n",
    "        multi_lead_ecgs[j, i, :] = full_data[lead][j]\n",
    "\n",
    "# Check the shape of the multi-lead ECG array\n",
    "print(multi_lead_ecgs.shape)  # should be (n_samples, ecg_leads, signal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, there are:\n",
    "* 181 ECG samples\n",
    "* 12 leads per sample\n",
    "* 2500 time points per lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first ECG sample (12 leads)\n",
    "sample_idx = 0\n",
    "fig, axs = plt.subplots(6, 2, figsize=(12, 10))\n",
    "fig.suptitle(f'ECG Sample {sample_idx}', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(multi_lead_ecgs[sample_idx, i])\n",
    "    ax.set_title(ecg_leads[i])\n",
    "    ax.set_xlim([0, signal_length])\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as sp\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Processes one sample ECG with all 12 leads\n",
    "def preprocess_ecg_signal(ecg_signals, fs=1000, target_fs=250, high=0.5, low=100.0):\n",
    "    \"\"\"\n",
    "    Preprocess a multi-lead ECG signal [timepoints, leads]:\n",
    "    - Resample to target_fs\n",
    "    - Bandpass filter between `high` and `low`\n",
    "    \"\"\"\n",
    "    timepoints = ecg_signals.shape[0] # Initially, 2500\n",
    "    new_timepoints = int(timepoints * target_fs / fs) # 625\n",
    "    \n",
    "    # Resample each lead using interpolation\n",
    "    ecg_resampled = np.zeros((new_timepoints, ecg_signals.shape[1]))\n",
    "    for lead in range(ecg_signals.shape[1]):\n",
    "        f = interp1d(np.arange(timepoints), ecg_signals[:, lead]) # Interpolation function from original points\n",
    "        ecg_resampled[:, lead] = f(np.linspace(0, timepoints - 1, new_timepoints)) # Create the new timeline\n",
    "\n",
    "    # Apply high-pass filter (remove slow drifts below 0.5 Hz)\n",
    "    b_high, a_high = sp.butter(2, high / (target_fs / 2), btype='high')\n",
    "    ecg_filtered = sp.filtfilt(b_high, a_high, ecg_resampled, axis=0)\n",
    "\n",
    "    # Apply low-pass filter (remove noise above 100 Hz)\n",
    "    b_low, a_low = sp.butter(2, low / (target_fs / 2), btype='low')\n",
    "    ecg_filtered = sp.filtfilt(b_low, a_low, ecg_filtered, axis=0)\n",
    "\n",
    "    return ecg_filtered # Return the signal with shape [625, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all ECGs\n",
    "preprocessed_ecgs = []\n",
    "for i in range(multi_lead_ecgs.shape[0]):\n",
    "    signal_raw = multi_lead_ecgs[i].T  # shape becomes [2500, 12] \n",
    "    processed = preprocess_ecg_signal(signal_raw) # Apply to each sample\n",
    "    preprocessed_ecgs.append(processed)\n",
    "    # preprocesses_ecgs becomes a list of arrays, each of shape [625, 12]\n",
    "\n",
    "# Try stacking into a 3D array\n",
    "# If all processed signals have identical  shape [625,12], they are stacked\n",
    "try:\n",
    "    preprocessed_ecgs = np.stack(preprocessed_ecgs)\n",
    "    print(\"All signals successfully preprocessed to shape:\", preprocessed_ecgs.shape)\n",
    "except:\n",
    "    print(\"Signals have different lengths. Stored as a list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the raw and preprocessed signals\n",
    "# Leads that might show more noise or differences after preprocessing\n",
    "leads_to_plot = ['I', 'AVR', 'V2']\n",
    "lead_indices = [ecg_leads.index(lead) for lead in leads_to_plot]\n",
    "\n",
    "# Raw and processed signals\n",
    "raw_signal = multi_lead_ecgs[i]  # [12, 2500]\n",
    "if isinstance(preprocessed_ecgs, list):\n",
    "    processed_signal = preprocessed_ecgs[i].T\n",
    "else:\n",
    "    processed_signal = preprocessed_ecgs[i].T  # [12, 625]\n",
    "\n",
    "# Time axes\n",
    "t_raw = np.linspace(0, 2.5, raw_signal.shape[1])        # 2500 samples at 1000 Hz\n",
    "t_processed = np.linspace(0, 2.5, processed_signal.shape[1])  # 625 samples at 250 Hz\n",
    "\n",
    "# Focus on first second only (for better detail)\n",
    "max_time = 1.0\n",
    "raw_mask = t_raw <= max_time\n",
    "proc_mask = t_processed <= max_time\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for k, lead_idx in enumerate(lead_indices):\n",
    "    plt.subplot(len(lead_indices), 1, k+1)\n",
    "    \n",
    "    plt.plot(t_raw[raw_mask], raw_signal[lead_idx][raw_mask], label='Raw (1000Hz)', alpha=0.6)\n",
    "    plt.plot(t_processed[proc_mask], processed_signal[lead_idx][proc_mask], label='Preprocessed (250Hz)', alpha=0.9)\n",
    "    \n",
    "    plt.title(f\"Lead {ecg_leads[lead_idx]}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map SOO to chamber (Left / Right /OTHER)\n",
    "# Load Hoja1 and Hoja2 from the mapping Excel file\n",
    "labels_path = \"data/labels_FontiersUnsupervised.xlsx\"\n",
    "map_hoja1 = pd.read_excel(labels_path, sheet_name=\"Hoja1\")\n",
    "map_hoja2 = pd.read_excel(labels_path, sheet_name=\"Hoja2\")\n",
    "\n",
    "# Build lookup dictionaries\n",
    "map_1 = dict(zip(map_hoja1[\"SOO\"], map_hoja1[\"SOO_Chamber\"]))\n",
    "map_2 = dict(zip(map_hoja2[\"SOO\"], map_hoja2[\"SOO_chamber\"]))\n",
    "\n",
    "# Step 1: Initial mapping using Hoja1\n",
    "simplified_chambers = []\n",
    "for entry in full_data[\"SOO\"]:\n",
    "    if isinstance(entry, str) and entry in map_1:\n",
    "        simplified_chambers.append(map_1[entry])\n",
    "    else:\n",
    "        simplified_chambers.append(\"OTHER\")\n",
    "\n",
    "# Step 2: Update entries marked as \"OTHER\" using Hoja2\n",
    "for i, entry in enumerate(full_data[\"SOO\"]):\n",
    "    if simplified_chambers[i] == \"OTHER\" and isinstance(entry, str) and entry in map_2:\n",
    "        simplified_chambers[i] = map_2[entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all unique chamber names after Hoja1 + Hoja2 mapping\n",
    "unique_chambers = sorted(set(simplified_chambers))\n",
    "print(\"Unique chamber labels found:\", len(unique_chambers))\n",
    "for label in unique_chambers:\n",
    "    print(\"-\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chamber(label):\n",
    "    \"\"\"\n",
    "    Normalize known chamber labels to: 'Left', 'Right', or 'OTHER'\n",
    "    \"\"\"\n",
    "    if label in [\"RVOT\", \"Right ventricle\", \"Tricuspid annulus\", \"Coronary sinus\"]:\n",
    "        return \"Right\"\n",
    "    elif label in [\"LVOT\", \"Left ventricle\", \"Mitral annulus\"]:\n",
    "        return \"Left\"\n",
    "    return \"OTHER\"\n",
    "\n",
    "final_chambers_normalized = [normalize_chamber(c) for c in simplified_chambers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram for Left vs Right Distribution\n",
    "\n",
    "# Filter out 'OTHER' samples\n",
    "filtered_labels = [label for label in final_chambers_normalized if label != \"OTHER\"]\n",
    "\n",
    "# Calculate histogram counts\n",
    "left_count = filtered_labels.count(\"Left\")\n",
    "right_count = filtered_labels.count(\"Right\")\n",
    "\n",
    "# Plot histogram for Left vs Right distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar([\"Left\", \"Right\"], [left_count, right_count], color=['tab:red', 'tab:blue'], edgecolor='black')\n",
    "\n",
    "plt.title(\"Class Distribution: Left vs Right Ventricle\")\n",
    "plt.xlabel(\"Chamber\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.grid(axis='y')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print counts of each class \n",
    "print(\"Left (0):\", left_count)\n",
    "print(\"Right (1):\", right_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 40 samples for Left and 140 for Right, our model  might favo the Right class, leading to biased predictions. We will augment the Left class with two data augmentation techniques: Gaussian noise addition and time shifting. Hence, for each Left sample, we will generate 2 augmented versions (via noise and time shifting), keeping the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for Left class\n",
    "import random\n",
    "\n",
    "def augment_ecg(ecg, noise_level=0.01, shift_range=10):\n",
    "    \"\"\"\n",
    "    Augment an ECG signal by adding noise and shifting the signal.\n",
    "    Parameters:\n",
    "    - ecg: The original ECG signal (numpy array).\n",
    "    - noise_level: The standard deviation of Gaussian noise to add.\n",
    "    - shift_range: The range within which to shift the signal (in samples).\n",
    "    Returns:\n",
    "    - augmented_versions: A list of augmented ECG signals.\n",
    "    \"\"\"\n",
    "    augmented_versions = []\n",
    "\n",
    "    # 1. Add Gaussian noise (white noise) to simulate sensor or environment noise\n",
    "    noise = ecg + np.random.normal(0, noise_level, ecg.shape)\n",
    "    augmented_versions.append(noise)\n",
    "\n",
    "    # 2. Time shift (circular roll), creating variation in the signal\n",
    "    shift = random.randint(-shift_range, shift_range)  # Random shift between -shift_range and +shift_range\n",
    "    shifted = np.roll(ecg, shift, axis=0)\n",
    "    augmented_versions.append(shifted)\n",
    "\n",
    "    return augmented_versions\n",
    "\n",
    "# Apply Data augmentation to Left-class samples \n",
    "\n",
    "# Separate original Left and Right class indices\n",
    "left_indices = [i for i, label in enumerate(final_chambers_normalized) if label == \"Left\"]\n",
    "right_indices = [i for i, label in enumerate(final_chambers_normalized) if label == \"Right\"]\n",
    "\n",
    "# Create augmented dataset\n",
    "X_augmented = []  # To store the augmented ECG signals\n",
    "y_augmented = []  # To store corresponding labels (0 for Left, 1 for Right)\n",
    "\n",
    "# Add all Right (label 1)\n",
    "for idx in right_indices:\n",
    "    X_augmented.append(preprocessed_ecgs[idx])\n",
    "    y_augmented.append(1)\n",
    "\n",
    "# Add original and 2x augmented Left (label 0)\n",
    "for idx in left_indices:\n",
    "    original = preprocessed_ecgs[idx]\n",
    "    X_augmented.append(original)\n",
    "    y_augmented.append(0)\n",
    "    for aug in augment_ecg(original):\n",
    "        X_augmented.append(aug)\n",
    "        y_augmented.append(0)\n",
    "\n",
    "# Convert lists to numpy arrays for further processing\n",
    "X_augmented = np.stack(X_augmented)  # Shape: (n_samples, timepoints, leads)\n",
    "y_augmented = np.array(y_augmented)  # Shape: (n_samples,)\n",
    "\n",
    "# Report balance and augmented dataset size\n",
    "print(\"\\nData Augmentation Complete\")\n",
    "print(\"X_augmented shape:\", X_augmented.shape)\n",
    "print(\"Left (0):\", np.sum(y_augmented == 0))  # Count how many \"Left\" samples\n",
    "print(\"Right (1):\", np.sum(y_augmented == 1))  # Count how many \"Right\" samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a Left-class ECG and its augmentations for lead V2 (index 7)\n",
    "\n",
    "def plot_ecg_comparison(original, augmented, lead=7, fs=250):\n",
    "    t = np.arange(original.shape[0]) / fs\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t, original[:, lead], label=\"Original\", linewidth=2)\n",
    "    for i, aug in enumerate(augmented):\n",
    "        plt.plot(t, aug[:, lead], label=f\"Augmented {i+1}\", linestyle='--')\n",
    "    plt.title(f\"ECG Lead {ecg_leads[lead]} â€” Original vs Augmented\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "left_example_idx = left_indices[0]\n",
    "original_signal = preprocessed_ecgs[left_example_idx]\n",
    "augmented_signals = augment_ecg(original_signal)\n",
    "plot_ecg_comparison(original_signal, augmented_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the final label (Left, Right, OTHER) as a column in our metadata DataFrame\n",
    "df_meta[\"normalized_label\"] = final_chambers_normalized\n",
    "print(df_meta.info())\n",
    "df_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_meta[df_meta[\"normalized_label\"].isin([\"Left\", \"Right\"])].copy()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have removed the sample labeled as OTHER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean[\"normalized_label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many missing values in different columns, so we must decide how to handle them. Since no columns have more than 40% missing values, we decided to impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns (median)\n",
    "numeric_columns = [\"Age\", \"Height\", \"Weight\", \"BMI\", \"CLINICAL_SCORE\"]\n",
    "df_clean[numeric_columns] = df_clean[numeric_columns].fillna(df_clean[numeric_columns].median())  # or use median()\n",
    "\n",
    "# Impute categorical columns (mode)\n",
    "categorical_columns = [\"Sex\", \"PVC_transition\", \"HTA\", \"DM\", \"DLP\", \"Smoker\", \"COPD\", \"Sleep_apnea\", \"OTorigin\"]\n",
    "df_clean[categorical_columns] = df_clean[categorical_columns].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Check remaining missing values\n",
    "print(df_clean.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompBioMed25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
